{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "290b51bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "# DenseNet121 model for image identification\n",
    "image_model = DenseNet121(weights='imagenet', include_top=False)\n",
    "\n",
    "#pooling layer\n",
    "x = image_model.output\n",
    "x = GlobalAveragePooling2D()(image_model.output)\n",
    "# fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1000, activation='softmax')(x)\n",
    "\n",
    "# Model to be trained\n",
    "dnModel = Model(inputs=image_model.input, outputs=predictions)\n",
    "\n",
    "# Freezing the image model layers incase further layers are needed\n",
    "for layer in image_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# model compilation\n",
    "dnModel.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be89cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#poem generation model\n",
    "\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# Load the Gutenberg dataset\n",
    "df = pd.read_parquet('gutenburg.parquet')\n",
    "\n",
    "# Remove lines that contain non-ASCII chars\n",
    "df = df[df['line'].map(lambda x: x.isascii())]\n",
    "\n",
    "# Join all lines into a single string of text\n",
    "text = df['line'].str.cat(sep=' ')\n",
    "\n",
    "# sorted list of unique chars and dicts mapping chars to indices and vice versa\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = {c: i for i, c in enumerate(chars)}\n",
    "indices_char = {i: c for i, c in enumerate(chars)}\n",
    "seqlen = 30  # sequence length, reduce if training time becomes an issue\n",
    "\n",
    "# create training data from gutenburg dataset\n",
    "def generator(sentence_list, next_word_list, batch_size):\n",
    "    index = 0\n",
    "    while True:\n",
    "        x = np.zeros((batch_size, seqlen, len(chars)), dtype=bool)\n",
    "        y = np.zeros((batch_size, len(chars)), dtype=bool)\n",
    "        for i in range(batch_size):\n",
    "            for t, w in enumerate(sentence_list[index % len(sentence_list)]):\n",
    "                x[i, t, char_indices[w]] = 1\n",
    "            y[i, char_indices[next_word_list[index % len(sentence_list)]]] = 1\n",
    "            index = index + 1\n",
    "        yield x, y\n",
    "        \n",
    "# declaration & loop for next chars and sentences\n",
    "sentences = []\n",
    "next_chars = []\n",
    "step = seqlen\n",
    "for i in range(0, len(text) - seqlen - 1, step):\n",
    "    sentences.append(text[i: i + seqlen])\n",
    "    next_chars.append(text[i + seqlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ad9ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model for poem generation\n",
    "model = Sequential()\n",
    "model.add(LSTM(120, input_shape=(seqlen, len(chars)), return_sequences=True))\n",
    "model.add(LSTM(120, return_sequences=True))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=0.01),\n",
    "    metrics=['categorical_crossentropy', 'accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cd526ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 30, 120)           105600    \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 30, 120)           115680    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 30, 99)            11979     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 233259 (911.17 KB)\n",
      "Trainable params: 233259 (911.17 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fd99391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper method for index sampling\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.exp(np.log(preds) / temperature)  # softmax\n",
    "    preds = preds / np.sum(preds)                #\n",
    "    probas = np.random.multinomial(1, preds, 1)  # sample index\n",
    "    return np.argmax(probas) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26ac0e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m1028\u001b[39m\n\u001b[0;32m     37\u001b[0m \u001b[39m#train model\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m model\u001b[39m.\u001b[39;49mfit(generator(sentences, next_chars, batch_size),\n\u001b[0;32m     39\u001b[0m           steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(\u001b[39mlen\u001b[39;49m(sentences)\u001b[39m/\u001b[39;49mbatch_size),\n\u001b[0;32m     40\u001b[0m           epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[0;32m     41\u001b[0m           callbacks\u001b[39m=\u001b[39;49m[print_callback])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:890\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    888\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    889\u001b[0m     \u001b[39m# no_variable_creation function.\u001b[39;00m\n\u001b[1;32m--> 890\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    891\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    892\u001b[0m   _, _, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[0;32m    893\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn\u001b[39m.\u001b[39m_function_spec  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    894\u001b[0m       \u001b[39m.\u001b[39mcanonicalize_function_inputs(\n\u001b[0;32m    895\u001b[0m           args, kwds))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#generate progress text after each epoch\n",
    "def on_epoch_end(epoch, _):\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - seqlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + seqlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "#set batch size\n",
    "batch_size = 1028\n",
    "\n",
    "#train model\n",
    "model.fit(generator(sentences, next_chars, batch_size),\n",
    "          steps_per_epoch=int(len(sentences)/batch_size),\n",
    "          epochs=50,\n",
    "          callbacks=[print_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d7210f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "# print out the size of the chars set\n",
    "print(len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca4855e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x2df147849a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('./2_by_120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58a52323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- diversity: 0.1\n",
      "----- Generating with seed: \"                    brown bear\"\n",
      "                    brown beard and the stars of the stars of the stars of the stars of the stars of the seas of the stars of the stars of the seas of the seas of the stars of the stars of the stars of the stars of the state, And \n",
      "----- diversity: 0.4\n",
      "----- Generating with seed: \"                    brown bear\"\n",
      "                    brown bears, and the state of the single spell. The heart was fair to be so free, The one ready heart of the stars of the souls of the parting of the stars of strength and the spear, She seizes to see, the suns\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"                    brown bear\"\n",
      "                    brown bearing into a part when the tales sing: While the strife of the walls and the trembling seas of sun, the summer talks of shadow; there is sense The shadows of the cares of seas the way, Some prize and th\n",
      "----- diversity: 0.6\n",
      "----- Generating with seed: \"                    brown bear\"\n",
      "                    brown beard still worked out in its bright stars Of the world at last, as the summer with the offence of the walls, Straightwarts the out, and smooth a day, The course of since a native spread; Revenge the door\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"                    brown bear\"\n",
      "                    brown bearS. The hour that viewers dove, winding away, but from the chat, With wild, and open wryng, With smooth scorns urb ful, their orwarty speaks to return them in from cool-pressus exter men, Who he drop w\n"
     ]
    }
   ],
   "source": [
    "start_index = random.randint(0, len(text) - seqlen - 1)\n",
    "\n",
    "for diversity in [.1,.4,.5,.6,1.0]:\n",
    "    print('----- diversity:', diversity)\n",
    "\n",
    "    generated = ''\n",
    "    #sentence = text[start_index: start_index + seqlen]\n",
    "    sentence = \"                    brown bear\"\n",
    "    sentence = sentence[0:seqlen]\n",
    "    generated += sentence\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(200):\n",
    "        x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)\n",
    "        next_index = sample(preds[0, -1], diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "223cc46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\x01', '\\x07', '\\t', '\\x1a', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "#poem generation model\n",
    "# Load the Gutenberg dataset\n",
    "# Data is re-loaded here to accommodate a different preprocessing form used before settling on the one above\n",
    "df = pd.read_parquet('gutenburg.parquet')\n",
    "\n",
    "# Remove lines that contain non-ASCII chars\n",
    "df = df[df['line'].map(lambda x: x.isascii())]\n",
    "\n",
    "chars = sorted(list(set(df['line'].str.cat(sep=' '))))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6cade68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 20, 26, 58, 109, 136, 151, 163, 207, 213, 214, 228, 230, 232, 246, 257, 258, 259, 261, 262, 263, 264, 266, 301, 304, 309, 312, 313, 315, 317, 323, 328, 348, 353, 390, 391, 392, 397, 400, 409, 413, 424, 438, 441, 442, 454, 458, 487, 574, 579, 591, 592, 594, 595, 596, 602, 610, 615, 617, 618, 651, 658, 679, 680, 691, 692, 703, 715, 772, 785, 791, 795, 835, 841, 845, 937, 941, 962, 981, 982, 995, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1019, 1020, 1021, 1030, 1031, 1034, 1035, 1040, 1041, 1042, 1045, 1054, 1057, 1062, 1141, 1151, 1165, 1166, 1186, 1199, 1211, 1229, 1238, 1246, 1247, 1279, 1280, 1287, 1304, 1317, 1321, 1322, 1333, 1358, 1365, 1381, 1382, 1383, 1393, 1418, 1459, 1469, 1471, 1505, 1506, 1525, 1543, 1544, 1545, 1567, 1568, 1612, 1645, 1664, 1719, 1727, 1728, 1731, 1745, 1746, 1830, 1847, 1852, 1855, 1894, 1919, 1924, 1934, 1953, 1958, 1962, 1974, 1978, 1995, 1996, 1997, 2002, 2003, 2008, 2080, 2136, 2151, 2161, 2199, 2294, 2303, 2304, 2334, 2378, 2381, 2383, 2388, 2428, 2487, 2490, 2491, 2507, 2558, 2615, 2619, 2620, 2621, 2622, 2665, 2666, 2670, 2678, 2679, 2732, 2817, 2819, 2824, 2863, 2888, 2997, 3021, 3023, 3026, 3039, 3059, 3160, 3167, 3168, 3170, 3228, 3232, 3238, 3255, 3257, 3295, 3305, 3468, 3473, 3477, 3525, 3545, 3628, 3636, 3650, 3665, 3692, 3697, 3698, 3753, 3757, 3759, 4006, 4007, 4009, 4010, 4027, 4072, 4096, 4099, 4207, 4253, 4272, 4295, 4331, 4332, 4369, 4399, 4513, 4530, 4549, 4556, 4560, 4654, 4678, 4679, 4696, 4697, 4730, 4756, 4758, 5098, 5101, 5184, 5185, 5186, 5198, 5408, 5428, 5625, 5720, 6076, 6081, 6130, 6150, 6268, 6269, 6270, 6271, 6272, 6273, 6274, 6375, 6438, 6519, 6520, 6522, 6574, 6619, 6652, 6670, 6686, 6763, 6794, 6795, 6796, 6797, 6859, 6956, 7122, 7164, 7321, 7391, 7394, 7409, 7846, 7848, 7889, 7928, 7971, 8187, 8197, 8426, 8433, 8565, 8672, 8779, 8780, 8781, 8782, 8783, 8784, 8785, 8786, 8787, 8788, 8789, 8790, 8791, 8792, 8793, 8794, 8795, 8796, 8797, 8798, 8799, 8800, 8820, 8905, 8912, 8930, 9093, 9372, 9388, 9399, 9465, 9575, 9576, 9577, 9578, 9579, 9580, 9612, 9825, 9842, 9870, 9889, 9989, 10122, 10140, 10469, 10493, 10557, 10602, 10671, 11014, 11073, 11101, 11150, 11333, 11351, 11435, 11439, 11689, 11985, 12109, 12116, 12241, 12242, 12286, 12413, 12475, 12664, 13086, 13118, 13167, 13213, 13646, 13647, 13648, 13649, 13650, 13983, 14005, 14019, 14020, 14410, 14460, 14495, 14531, 14591, 14757, 14869, 14906, 14959, 14993, 15370, 15390, 15524, 15529, 15553, 15612, 15618, 15809, 15834, 15937, 16059, 16081, 16251, 16265, 16362, 16376, 16436, 16452, 16568, 16632, 16686, 16688, 16904, 17102, 17104, 17135, 17192, 17254, 17270, 17283, 17364, 17382, 17393, 17448, 17568, 17604, 17630, 17764, 17779, 17933, 18007, 18238, 18287, 18396, 18466, 18500, 18619, 18720, 18908, 18937, 19084, 19096, 19170, 19221, 19226, 19363, 19385, 19389, 19482, 19525, 19529, 19722, 19871, 20072, 20113, 20179, 20181, 20378, 20586, 20652, 20956, 21025, 21029, 21210, 21566, 21700, 21765, 21769, 21784, 21874, 22032, 22142, 22229, 22374, 22382, 22403, 22421, 22535, 22803, 22848, 22888, 23037, 23111, 23196, 23245, 23281, 23305, 23314, 23316, 23318, 23336, 23338, 23348, 23350, 23353, 23404, 23431, 23433, 23436, 23454, 23455, 23456, 23457, 23459, 23460, 23467, 23480, 23482, 23545, 23665, 23684, 23819, 23972, 24011, 24018, 24019, 24083, 24108, 24117, 24125, 24167, 24191, 24199, 24216, 24258, 24262, 24269, 24280, 24298, 24308, 24312, 24331, 24334, 24336, 24363, 24364, 24405, 24449, 24465, 24485, 24530, 24560, 24605, 24611, 24623, 24644, 24662, 24673, 24679, 24694, 24734, 24736, 24760, 24778, 24795, 24815, 24819, 24825, 24834, 24840, 24849, 24856, 24869, 24894, 25008, 25055, 25153, 25281, 25340, 25426, 25442, 25455, 25458, 25546, 25553, 25592, 25599, 25608, 25609, 25610, 25611, 25617, 25621, 25631, 25634, 25639, 25643, 25657, 25681, 25698, 25733, 25794, 25880, 25942, 25953, 25961, 25965, 25979, 26036, 26060, 26073, 26199, 26275, 26333, 26383, 26388, 26398, 26431, 26437, 26445, 26505, 26611, 26626, 26650, 26675, 26715, 26736, 26785, 26787, 26788, 26790, 26791, 26792, 26793, 26796, 26802, 26803, 26805, 26831, 26832, 26833, 26834, 26861, 26864, 26874, 26916, 26918, 26937, 27024, 27069, 27126, 27129, 27130, 27139, 27175, 27176, 27179, 27182, 27195, 27199, 27221, 27275, 27297, 27333, 27336, 27370, 27391, 27396, 27401, 27405, 27406, 27407, 27408, 27409, 27424, 27441, 27473, 27474, 27494, 27530, 27534, 27663, 27677, 27700, 27727, 27731, 27735, 27739, 27770, 27776, 27781, 27849, 27851, 27864, 27870, 27885, 27912, 27971, 28032, 28043, 28184, 28218, 28260, 28287, 28352, 28375, 28434, 28591, 28621, 28660, 28665, 28666, 28722, 28744, 28796, 28816, 28824, 28830, 28847, 28903, 29210, 29324, 29345, 29357, 29358, 29378, 29515, 29521, 29531, 29552, 29574, 29606, 29700, 29722, 29732, 29795, 29840, 29879, 29993, 30023, 30038, 30184, 30185, 30198, 30225, 30235, 30272, 30276, 30279, 30282, 30327, 30332, 30357, 30391, 30420, 30426, 30481, 30488, 30494, 30501, 30568, 30599, 30652, 30659, 30669, 30672, 30687, 30690, 30720, 30730, 30795, 30842, 31015, 31027, 31036, 31172, 31184, 31272, 31283, 31303, 31304, 31305, 31314, 31342, 31466, 31467, 31486, 31591, 31594, 31706, 31712, 31726, 31764, 31874, 31877, 31878, 31890, 31896, 31913, 31919, 31926, 31928, 31959, 31967, 31968, 32030, 32091, 32099, 32110, 32145, 32146, 32153, 32167, 32184, 32190, 32210, 32233, 32262, 32275, 32276, 32277, 32335, 32373, 32445, 32452, 32456, 32458, 32459, 32477, 32491, 32493, 32499, 32503, 32523, 32528, 32532, 32553, 32767, 32772, 32778, 32944, 32986, 32990, 33023, 33073, 33089, 33112, 33149, 33150, 33156, 33171, 33193, 33363, 33417, 33441, 33456, 33457, 33486, 33533, 33552, 33553, 33555, 33629, 33658, 33674, 33681, 33686, 33691, 33730, 33732, 33758, 33768, 33770, 33774, 33786, 33792, 33855, 33902, 33940, 34001, 34015, 34027, 34050, 34113, 34117, 34159, 34163, 34215, 34227, 34234, 34235, 34237, 34269, 34298, 34331, 34409, 34438, 34665, 34741, 34752, 34762, 34780, 34790, 34821, 34870, 34936, 34966, 34982, 35033, 35051, 35059, 35098, 35115, 35174, 35188, 35190, 35193, 35227, 35243, 35260, 35279, 35287, 35357, 35394, 35402, 35411, 35452, 35475, 35479, 35497, 35515, 35524, 35536, 35546, 35553, 35612, 35667, 35714, 35777, 35779, 35780, 35848, 35903, 35907, 35922, 35991, 35996, 36005, 36038, 36051, 36068, 36091, 36094, 36098, 36135, 36137, 36149, 36150, 36153, 36168, 36214, 36287, 36305, 36321, 36337, 36441, 36501, 36508, 36543, 36617, 36618, 36620, 36637, 36661, 36664, 36702, 36737, 36770, 36773, 36782, 36803, 36831, 36841, 36865, 36913, 36915, 36916, 36925, 36935, 36954, 36980, 37074, 37085, 37086, 37087, 37091, 37132, 37154, 37155, 37188, 37213, 37214, 37323, 37365, 37366, 37367, 37371, 37375, 37414, 37452, 37469, 37510, 37518, 37529, 37542, 37543, 37556, 37557, 37648, 37649, 37655, 37690, 37718, 37751, 37752, 37804, 37810, 37845, 37852, 37859, 37860, 37861, 37867, 37938, 37980, 37999, 38011, 38052, 38071, 38135, 38174, 38230, 38275, 38407, 38410, 38438, 38463, 38468, 38475, 38503, 38511, 38520, 38529, 38549, 38550, 38562, 38565, 38566, 38572, 38594, 38599, 38741, 38766, 38839, 38856, 38857, 38877, 38880, 38898, 38902, 38927, 39028, 39032, 39037, 39128, 39131, 39132, 39198, 39236, 39475, 39494, 39496, 39499, 39614, 39626, 39638, 39656, 39741, 39750, 39783, 39784, 39796, 39797, 39798, 39804, 39821, 39844, 39909, 40124, 40134, 40152, 40188, 40200, 40237, 40344, 40345, 40379, 40425, 40442, 40444, 40462, 40490, 40560, 40562, 40598, 40622, 40717, 40786, 40852, 40895, 40906, 41016, 41026, 41059, 41076, 41077, 41162, 41215, 41216, 41230, 41397, 41466, 41467, 41468, 41537, 41615, 41691, 41693, 41760, 41808, 41810, 41865, 41944, 41945, 41955, 41985, 42034, 42041, 42051, 42052, 42058, 42076, 42134, 42162, 42166, 42171, 42181, 42265, 42290, 42299, 42301, 42306, 42330, 42392, 42407, 42422, 42439, 42543, 42553, 42667, 42668, 43271, 43406, 44201, 45066, 45082, 45199, 45292, 45470, 47383, 48323]\n",
      "1191\n",
      "[26793, 24673, 39750, 30023, 315, 24269, 1525, 24644, 32275, 30426, 2679, 41397, 28621, 25880, 23456, 33902, 38275, 8780, 263, 24834, 38550, 34235, 8782, 41615, 28184, 37804, 3545, 24795, 27441, 34027, 772, 35190, 18238, 1728, 29515, 1383, 24125, 29210, 28184, 26437, 33193, 17630, 1645, 39798, 18466, 6076, 34982, 23353, 3021, 40562]\n",
      "                                               line  gutenberg_id\n",
      "70927         \"Mine is no horse with wings, to gain           263\n",
      "70928              The region of the Spheral chime;           263\n",
      "70929             He does but drag a rumbling wain,           263\n",
      "70930       Cheered by the coupled bells of rhyme.\"           263\n",
      "70931    Gentlest of critics, does your memory hold           263\n",
      "...                                             ...           ...\n",
      "2984964         Accept the words of love and truth:         41615\n",
      "2984965        _Not all is gold with golden gleam,_         41615\n",
      "2984966    _Not all are friends who friendly seem;_         41615\n",
      "2984967  _The_ TRIED, _the_ TRUSTED _and the_ TRUE,         41615\n",
      "2984968    _These are the friends we name for you._         41615\n",
      "\n",
      "[125986 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "ids = set()\n",
    "# print each unique gutenberg id\n",
    "for id in df['gutenberg_id']:\n",
    "    ids.add(id)\n",
    "print(sorted(ids))\n",
    "print(len(ids))\n",
    "\n",
    "# append each line of the randomly selected \n",
    "\n",
    "train_ids = random.choices(list(ids), k= 50)\n",
    "print(train_ids)\n",
    "\n",
    "t = df.loc[df['gutenberg_id'].isin(train_ids)]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43619a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5289334\n"
     ]
    }
   ],
   "source": [
    "# Join all lines into a single string of text\n",
    "text = t['line'].str.cat(sep=' ')\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51071694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "# sorted list of unique chars and dicts mapping chars to indices and vice versa\n",
    "chars = sorted(list(set(df['line'].str.cat(sep=' ')))) # should be changed to set(df['line']) in order to allow for evaluation\n",
    "print(len(chars))\n",
    "char_indices = {c: i for i, c in enumerate(chars)}\n",
    "indices_char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7660e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlen = 60\n",
    "step = seqlen\n",
    "sentences = []\n",
    "for i in range(0, len(text) - seqlen - 1, step):\n",
    "    sentences.append(text[i: i + seqlen + 1])\n",
    "\n",
    "x = np.zeros((len(sentences), seqlen, len(chars)), dtype=bool)\n",
    "y = np.zeros((len(sentences), seqlen, len(chars)), dtype=bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, (char_in, char_out) in enumerate(zip(sentence[:-1], sentence[1:])):\n",
    "        x[i, t, char_indices[char_in]] = 1\n",
    "        y[i, t, char_indices[char_out]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f35495b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 17\u001b[0m\n\u001b[0;32m     10\u001b[0m model1\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m     11\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m     optimizer\u001b[39m=\u001b[39mRMSprop(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m),\n\u001b[0;32m     13\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     15\u001b[0m \u001b[39m# test performance across the 150 poem example dataset\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m# 10 epochs each model\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m h1 \u001b[39m=\u001b[39m model1\u001b[39m.\u001b[39;49mfit(x,y,\n\u001b[0;32m     18\u001b[0m          batch_size\u001b[39m=\u001b[39;49m batch_size,\n\u001b[0;32m     19\u001b[0m          epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m     20\u001b[0m          verbose\u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Comparing evaluation metrics across several different architectures\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create models for cross-comparison\n",
    "model1 = Sequential()\n",
    "model1.add(LSTM(120, input_shape=(seqlen, len(chars)), return_sequences=True))\n",
    "model1.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "# compile the models\n",
    "model1.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=0.01),\n",
    "    metrics=['categorical_crossentropy', 'accuracy'])\n",
    "\n",
    "# test performance across the 150 poem example dataset\n",
    "# 10 epochs each model\n",
    "h1 = model1.fit(x,y,\n",
    "         batch_size= batch_size,\n",
    "         epochs=10,\n",
    "         verbose= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e540344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(LSTM(120, input_shape=(seqlen, len(chars)), return_sequences=True))\n",
    "model1.add(LSTM(120, return_sequences=True))\n",
    "model1.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model1.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=0.01),\n",
    "    metrics=['categorical_crossentropy', 'accuracy'])\n",
    "\n",
    "h2 = model1.fit(generator(sentences, next_chars, batch_size),\n",
    "        steps_per_epoch=int(len(sentences)/batch_size),\n",
    "         batch_size= batch_size,\n",
    "         epochs=10,\n",
    "         verbose= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ba3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(LSTM(64, input_shape=(seqlen, len(chars)), return_sequences=True))\n",
    "model1.add(LSTM(64, return_sequences=True))\n",
    "model1.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model1.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=0.01),\n",
    "    metrics=['categorical_crossentropy', 'accuracy'])\n",
    "\n",
    "h3 = model1.fit(x,y,\n",
    "         batch_size= batch_size,\n",
    "         epochs=10,\n",
    "         verbose= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2264ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(LSTM(256, input_shape=(seqlen, len(chars)), return_sequences=True))\n",
    "model1.add(LSTM(256, return_sequences=True))\n",
    "model1.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model1.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=0.01),\n",
    "    metrics=['categorical_crossentropy', 'accuracy'])\n",
    "\n",
    "h4 = model1.fit(x,y,\n",
    "         batch_size= batch_size,\n",
    "         epochs=10,\n",
    "         verbose= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd2e62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(h1.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce07f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h1.history['accuracy'])\n",
    "plt.plot(h2.history['accuracy'])\n",
    "plt.plot(h3.history['accuracy'])\n",
    "plt.plot(h4.history['accuracy'])\n",
    "plt.title('Accuracy Comparison of Different Models')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['1x120_layer', '2x120_layers', '2x64_layers', '2x256_layers'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.savefig(\"accuracy_comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc91a4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h1.history['loss'])\n",
    "plt.plot(h2.history['loss'])\n",
    "plt.plot(h3.history['loss'])\n",
    "plt.plot(h4.history['loss'])\n",
    "plt.title('Loss Comparison of Different Models')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['1x120_layer', '2x120_layers', '2x64_layers', '2x256_layers'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"loss_comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9180f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h1.history['categorical_crossentropy'])\n",
    "plt.plot(h2.history['categorical_crossentropy'])\n",
    "plt.plot(h3.history['categorical_crossentropy'])\n",
    "plt.plot(h4.history['categorical_crossentropy'])\n",
    "plt.title('Categorical Crossentropy Comparison of Different Models')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['1x120_layer', '2x120_layers', '2x64_layers', '2x256_layers'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"entropy_comparison\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
